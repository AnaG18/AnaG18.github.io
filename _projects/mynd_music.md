---
layout: page
title: Mynd Music
description: a project that redirects to another website
img: assets/img/mynd_logo.png
importance: 1
category: 2022
---

Technology has been an excellent tool to be in touch with people around the globe, but lately it has heavenly influenced our attention span and interactions towards the outside world. In this way, Mynd Music is a smell-enhanced virtual experience, along with real time EEG acquisition, that offers a nuanced understanding of our emotions and expression of them. During this art installation, the participant uses two EEG headsets -Muse 2, and Enophone- while being immersed in a virtual reality environment visiting different scenarios with their own scented stimuli -produced by Aroma Shooter®- to induce an emotional reaction. Meanwhile, the EEG signal is processed using frontal alpha asymmetry, along with relative beta and alpha power to correlate the readings with emotional states such as concentration, relaxation, and approach/avoidance oriented behaviors. The music is selected with machine learning algorithms to resemble the emotional state. Thus, the final melody is unique in every interaction with the VR environment, as our brain has different reactions. This diversity allows for exploration, communication, and understanding of our emotions in a way words can not express, but can be captured by a melody. Mynd Music is an acoustic re-interpretation of the physiological manifestation of an emotional state.

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/mynd_quest.jpeg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/mynd_muse.jpeg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/mynd_eno.jpeg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/mynd_aroma.jpeg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/mynd_rasp.jpeg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Equipment used in this project
</div>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/mynd_setup.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    All the equipment required for the installation displayed in a single exhibition.
</div>

The first iteration of this installation was presented at INC Monterrey Festival 2022, as one of the four winning exhibits of the 2021 Fund of the Art, Science, and Technology Laboratory of the Art Institute CSO and Tecnológico de Monterrey. Entering a 3 m × 3 m space, viewers were able to sit down and get connected to all devices (VR headset, Muse 2, and Enophone). Then, the user is registered, introducing their name into the GUI. One of the artists made sure all devices were properly connected to the GUI and triggered the experience from the Raspberry Pi. In the VR environment, different scenarios, scents, and sounds were displayed for the viewer, while their brainwaves were being processed and analyzed in real time. 

<div class="row justify-content-sm-center">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/mynd_inc.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/mynd_schematic.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    On the left, we can see the Mynd Music exhibition at INC Monterrey while its being used. On the right, a flowchart for the data processing algorithm.
</div>

This project received its funding by the Arts, Science, and Technology Laboratory of the Art Institute CSO and Tecnologico de Monterrey. This project was done in collaboration with María Fernanda Velázquez Vergara, José Esteban Romero Gómez, Juan Pablo Bañuelos Mayer under the supervision of Dr. Myriam Alanis Espinosa.  

In the present case, the authors would like to thank Fabian de Jesús Nuño Orozco for his help in designing the code for real-time frontal alpha symmetry processing using Python. We also recognize and thank Andrés Ortiz Trejo for his mentoring in music theory to represent emotions, and composing individualized pieces of the repertoire from which we are able to extract fragments to create each unique melody. Special thanks to María Fernanda González Espinoza for managing our Instagram and Website.

During this research, all experimental procedures were conducted with informed consent by the human participants through an official consent letter. 

